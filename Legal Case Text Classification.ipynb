{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Decisão</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>parcialmente provido</td>\n",
       "      <td>conhecido. parcialmente provido. unanime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>desprovido</td>\n",
       "      <td>conhecido. improvido. unânime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>parcialmente provido</td>\n",
       "      <td>conhecido. parcialmente provido. unânime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>desprovido</td>\n",
       "      <td>conhecer em parte. negar provimento. unânime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>desprovido</td>\n",
       "      <td>conhecer do recurso e negar-lhe provimento. un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>provido</td>\n",
       "      <td>conhecido. provido. unânime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>desprovido</td>\n",
       "      <td>apelação da autora e recurso adesivo da ré con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>desprovido</td>\n",
       "      <td>conhecido. preliminar rejeitada. prejudicial r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>parcialmente provido</td>\n",
       "      <td>dar parcial provimento ao recurso de m.c.b.s.r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>desprovido</td>\n",
       "      <td>conhecer do recurso e negar-lhe provimento.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Status                                            Decisão\n",
       "0  parcialmente provido           conhecido. parcialmente provido. unanime\n",
       "1            desprovido                      conhecido. improvido. unânime\n",
       "2  parcialmente provido           conhecido. parcialmente provido. unânime\n",
       "3            desprovido       conhecer em parte. negar provimento. unânime\n",
       "4            desprovido  conhecer do recurso e negar-lhe provimento. un...\n",
       "5               provido                       conhecido. provido. unânime.\n",
       "6            desprovido  apelação da autora e recurso adesivo da ré con...\n",
       "7            desprovido  conhecido. preliminar rejeitada. prejudicial r...\n",
       "8  parcialmente provido  dar parcial provimento ao recurso de m.c.b.s.r...\n",
       "9            desprovido        conhecer do recurso e negar-lhe provimento."
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the spam data\n",
    "# ham is the label for non-spam messages\n",
    "spam = pd.read_excel('test.xlsx')\n",
    "spam.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank(\"pt\")\n",
    "\n",
    "# Create the TextCategorizer with exclusive classes and \"bow\" architecture\n",
    "textcat = nlp.create_pipe(\n",
    "              \"textcat\",\n",
    "              config={\n",
    "                \"exclusive_classes\": True,\n",
    "                \"architecture\": \"bow\"})\n",
    "\n",
    "# Add the TextCategorizer to the empty model\n",
    "nlp.add_pipe(textcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add labels to text classifier\n",
    "textcat.add_label(\"provido\")\n",
    "textcat.add_label(\"desprovido\")\n",
    "textcat.add_label(\"parcialmente provido\")\n",
    "textcat.add_label(\"parcialmente improvido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = spam['Decisão'].values\n",
    "train_labels = [{'cats': {'provido': label == 'provido',\n",
    "                          'desprovido': label == 'desprovido',\n",
    "                          'parcialmente provido': label == 'parcialmente provido',\n",
    "                          'parcialmente improvido': label == 'parcialmente improvido',\n",
    "                         }\n",
    "                } \n",
    "                for label in spam['Status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conhecido. parcialmente provido. unanime',\n",
       "  {'cats': {'provido': False,\n",
       "    'desprovido': False,\n",
       "    'parcialmente provido': True,\n",
       "    'parcialmente improvido': False}}),\n",
       " ('conhecido. improvido. unânime',\n",
       "  {'cats': {'provido': False,\n",
       "    'desprovido': True,\n",
       "    'parcialmente provido': False,\n",
       "    'parcialmente improvido': False}}),\n",
       " ('conhecido. parcialmente provido. unânime',\n",
       "  {'cats': {'provido': False,\n",
       "    'desprovido': False,\n",
       "    'parcialmente provido': True,\n",
       "    'parcialmente improvido': False}})]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = list(zip(train_texts, train_labels))\n",
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch\n",
    "\n",
    "spacy.util.fix_random_seed(1)\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "# Create the batch generator with batch size = 8\n",
    "batches = minibatch(train_data, size=8)\n",
    "# Iterate through minibatches\n",
    "for batch in batches:\n",
    "    # Each batch is a list of (text, label) but we need to\n",
    "    # send separate lists for texts and labels to update().\n",
    "    # This is a quick way to split a list of tuples into lists\n",
    "    texts, labels = zip(*batch)\n",
    "    nlp.update(texts, labels, sgd=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'textcat': 0.6548962322995067}\n",
      "{'textcat': 1.286041172221303}\n",
      "{'textcat': 1.8963963678106666}\n",
      "{'textcat': 2.4987501250579953}\n",
      "{'textcat': 3.1268228692933917}\n",
      "{'textcat': 3.8827230846509337}\n",
      "{'textcat': 4.3834200175479054}\n",
      "{'textcat': 5.002194302622229}\n",
      "{'textcat': 5.44556794827804}\n",
      "{'textcat': 5.785625381860882}\n",
      "{'textcat': 6.3442628756165504}\n",
      "{'textcat': 6.831632277928293}\n",
      "{'textcat': 7.365547354333103}\n",
      "{'textcat': 7.885119690559804}\n",
      "{'textcat': 8.348310220986605}\n",
      "{'textcat': 8.886866567190737}\n",
      "{'textcat': 8.969448438379914}\n",
      "{'textcat': 9.171361861284822}\n",
      "{'textcat': 9.762848474085331}\n",
      "{'textcat': 10.263680576812476}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "spacy.util.fix_random_seed(1)\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "losses = {}\n",
    "for epoch in range(20):\n",
    "    random.shuffle(train_data)\n",
    "    # Create the batch generator with batch size = 8\n",
    "    batches = minibatch(train_data, size=8)\n",
    "    # Iterate through minibatches\n",
    "    for batch in batches:\n",
    "        # Each batch is a list of (text, label) but we need to\n",
    "        # send separate lists for texts and labels to update().\n",
    "        # This is a quick way to split a list of tuples into lists\n",
    "        texts, labels = zip(*batch)\n",
    "        nlp.update(texts, labels, sgd=optimizer, losses=losses)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19849427 0.63169545 0.12702602 0.04278427]\n",
      " [0.32756126 0.23919512 0.17616656 0.2570771 ]\n",
      " [0.11642125 0.20333734 0.5724111  0.10783035]\n",
      " [0.35534903 0.28463045 0.19674794 0.16327254]]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"conhecer do recurso e negar-lhe provimento. unânime.\", \n",
    "         \"conhecer. dar parcial improvimento. unânime\",\n",
    "         \"apelação parcialmente conhecida e parcialmente provida. unânime.\",\n",
    "         \"prover-lhe provimento\"]\n",
    "docs = [nlp.tokenizer(text) for text in texts]   \n",
    "# Use textcat to get the scores for each doc\n",
    "textcat = nlp.get_pipe('textcat')\n",
    "scores, _ = textcat.predict(docs)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['desprovido', 'provido', 'parcialmente provido', 'provido']\n"
     ]
    }
   ],
   "source": [
    "# From the scores, find the label with the highest score/probability\n",
    "predicted_labels = scores.argmax(axis=1)\n",
    "print([textcat.labels[label] for label in predicted_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6694\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('Dados.xlsx', index=False, usecols = [7])  \n",
    "my_texts = []\n",
    "for i in df.values.tolist():\n",
    "    my_texts.append(str(i[0]).lower())\n",
    "    \n",
    "print(len(my_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negou-se provimento aos recursos. unânime', 'conhecer. rejeitar preliminar. negar provimento.unânime', 'negar provimento. unânime', 'negar provimento. unânime', 'conhecer e dar parcial provimento, unânime', 'conhecido. negou-se provimento. unânime', 'conhecido. negou-se provimento. unânime', 'conhecido. negou-se provimento. unânime', 'conhecer e negar provimento, unânime', 'conhecer e negar provimento, unânime', 'acolher a preliminar de ilegitimidade passiva dosegundo réu para julgar extinto o processo em relação a ele.dar parcial provimento ao recurso da primeira ré. unânime', 'conhecer e negar provimento, unânime', 'conhecer e dar parcial provimento, unânime', 'dar parcial provimento ao recurso do autor. darparcial provimento ao recurso dos réus. unânime', 'conhecer. negar provimento. unânime', 'conhecido. desprovido. unânime', 'conhecer do apelo da 2ª ré e negar provimento.conhecer em parte do apelo do autor e dar parcial provimento.unânime', 'conhecido. desprovido. unânime', 'conhecido. provido. unânime', 'conhecido. provido. unânime', 'conhecer. negar provimento. unânime', 'conhecer. dar parcial provimento. unânime', 'conhecer. dar parcial provimento. unânime', 'conhecer, rejeitar a(s) preliminar(es) e, no mérito,dar parcial provimento, unânime', 'conhecer do recurso da denunciada à lide e darparcial provimento. conhecer em parte do recurso do réudenunciado e negar provimento, unânime']\n",
      "[[0.33446476 0.47495985 0.11828215 0.07229327]\n",
      " [0.19137925 0.5320499  0.18055132 0.09601956]\n",
      " [0.2817485  0.4452224  0.17577839 0.09725068]\n",
      " [0.2817485  0.4452224  0.17577839 0.09725068]\n",
      " [0.2329438  0.2991765  0.2916911  0.1761886 ]\n",
      " [0.3210065  0.46833915 0.1463282  0.06432615]\n",
      " [0.3210065  0.46833915 0.1463282  0.06432615]\n",
      " [0.3210065  0.46833915 0.1463282  0.06432615]\n",
      " [0.17780654 0.50077343 0.23161574 0.08980429]\n",
      " [0.17780654 0.50077343 0.23161574 0.08980429]\n",
      " [0.29523498 0.3578842  0.32392305 0.02295777]\n",
      " [0.17780654 0.50077343 0.23161574 0.08980429]\n",
      " [0.2329438  0.2991765  0.2916911  0.1761886 ]\n",
      " [0.43932995 0.3014656  0.2353195  0.02388497]\n",
      " [0.28353602 0.5092996  0.13431776 0.07284666]\n",
      " [0.3078092  0.44617152 0.15986711 0.08615215]\n",
      " [0.01859189 0.70743567 0.22414678 0.04982577]\n",
      " [0.3078092  0.44617152 0.15986711 0.08615215]\n",
      " [0.44167584 0.27129242 0.21089552 0.07613615]\n",
      " [0.44167584 0.27129242 0.21089552 0.07613615]\n",
      " [0.28353602 0.5092996  0.13431776 0.07284666]\n",
      " [0.37604538 0.30802655 0.17124465 0.14468347]\n",
      " [0.37604538 0.30802655 0.17124465 0.14468347]\n",
      " [0.16432418 0.17728381 0.59862924 0.05976273]\n",
      " [0.02937735 0.9147397  0.05110753 0.00477535]]\n"
     ]
    }
   ],
   "source": [
    "my_texts = my_texts[:25]\n",
    "print(my_texts)\n",
    "docs = [nlp.tokenizer(a) for a in my_texts]\n",
    "    \n",
    "# Use textcat to get the scores for each doc\n",
    "textcat = nlp.get_pipe('textcat')\n",
    "scores, _ = textcat.predict(docs)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['desprovido', 'desprovido', 'desprovido', 'desprovido', 'desprovido', 'desprovido', 'desprovido', 'desprovido', 'desprovido', 'desprovido', 'desprovido', 'desprovido', 'desprovido', 'provido', 'desprovido', 'desprovido', 'desprovido', 'desprovido', 'provido', 'provido', 'desprovido', 'provido', 'provido', 'parcialmente provido', 'desprovido']\n"
     ]
    }
   ],
   "source": [
    "# From the scores, find the label with the highest score/probability\n",
    "predicted_labels = scores.argmax(axis=1)\n",
    "print([textcat.labels[label] for label in predicted_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
